{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMUND+TVUEE+/r/4wkTkuH5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","# Edge-aware EA-NAS for MNIST (subset=10k) with NSGA-II\n","# - Optimize accuracy, cost (params normalized by bitwidth), and latency (quantization proxy)\n","# - Train/Test split for credible reporting\n","# - Baseline comparison (bütçe-dışı ve bütçe-içi) + final test evaluation\n","# - Top-10'u uzun eğitimle testte yeniden değerlendirip şampiyonu seçer\n","# Colab-ready\n","\n","# Install DEAP if needed\n","try:\n","    import deap\n","except ImportError:\n","    import sys\n","    !{sys.executable} -m pip -q install deap\n","\n","import random\n","import time\n","import numpy as np\n","import pandas as pd\n","\n","from deap import base, creator, tools, algorithms\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","# ===============================\n","# Reproducibility\n","# ===============================\n","RANDOM_SEED = 42\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","\n","# ===============================\n","# Global Settings (MNIST)\n","# ===============================\n","ALPHA = 0.8  # scalar report weighting (only for reporting, EA is multi-objective)\n","BETA = 0.2\n","\n","# Search space (kept moderate for speed; can widen later)\n","LAYER_MIN = 1\n","LAYER_MAX = 4\n","NEURON_MIN = 8\n","NEURON_MAX = 64\n","\n","ACTIVATIONS = [\"relu\", \"tanh\", \"logistic\"]\n","ALPHAS = [1e-5, 1e-4, 1e-3, 1e-2]\n","LRS = [0.0005, 0.001, 0.003, 0.01, 0.03]\n","BATCH_SIZES = [32, 64, 128, 256]\n","BITWIDTHS = [8, 16, 32]  # quantization simulation\n","\n","# Resource budget (for 32-bit baseline; cost normalized with bitwidth)\n","MAX_PARAMETRE = 50_000\n","\n","# CV and latency (speed-tuned)\n","CV_FOLDS = 2\n","LAT_REPEATS = 2\n","WARMUP = 1\n","ETA_LAT = 0.7  # latency proxy exponent: (bit/32)^ETA_LAT\n","\n","# EA (NSGA-II) params\n","POP_SIZE = 30\n","NGEN = 10\n","CXPB = 0.6\n","CX_INDPB = 0.5\n","MUTPB = 0.7\n","MUT_INDPB = 0.3\n","\n","# Mutation biases\n","LAYER_MUTPB = 0.2\n","REDUCE_DELTAS = [-8, -6, -4, -2, 0, +2, +4, +6, +8]\n","REDUCE_WEIGHTS = [0.20, 0.16, 0.14, 0.12, 0.08, 0.10, 0.08, 0.07, 0.05]\n","\n","# Subset size\n","SUBSET_SIZE = 10_000\n","\n","# ===============================\n","# Data (MNIST) + 10k subset + Train/Test split\n","# ===============================\n","print(\"MNIST indiriliyor (OpenML)...\")\n","mn = fetch_openml('mnist_784', version=1, as_frame=False)\n","X_full = mn.data.astype(np.float32)\n","y_full = mn.target.astype(str).astype(np.int32)\n","\n","sss = StratifiedShuffleSplit(n_splits=1, train_size=SUBSET_SIZE, random_state=RANDOM_SEED)\n","idx_train, _ = next(sss.split(X_full, y_full))\n","X_subset = X_full[idx_train]\n","y_subset = y_full[idx_train]\n","\n","INPUT_DIM = X_subset.shape[1]  # 784\n","OUTPUT_DIM = len(np.unique(y_subset))  # 10\n","print(f\"Subset hazır: X.shape={X_subset.shape}, sınıf sayısı={OUTPUT_DIM}\")\n","\n","# Train/Test split (EA trains on train only; final report uses test)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_subset, y_subset, test_size=0.2, stratify=y_subset, random_state=RANDOM_SEED\n",")\n","\n","# ===============================\n","# DEAP Creator\n","# ===============================\n","def safe_creator():\n","    if not hasattr(creator, \"RA_FitnessMulti\"):\n","        creator.create(\"RA_FitnessMulti\", base.Fitness, weights=(1.0, -1.0, -1.0))  # max acc, min cost, min latency\n","    if not hasattr(creator, \"RA_Individual\"):\n","        creator.create(\"RA_Individual\", list, fitness=creator.RA_FitnessMulti)\n","safe_creator()\n","\n","toolbox = base.Toolbox()\n","\n","# ===============================\n","# Individual init\n","# ===============================\n","def init_individual():\n","    layer_count = random.randint(LAYER_MIN, LAYER_MAX)\n","    neurons = [random.randint(NEURON_MIN, NEURON_MAX) for _ in range(LAYER_MAX)]\n","    act_idx = random.randrange(len(ACTIVATIONS))\n","    alpha_idx = random.randrange(len(ALPHAS))\n","    lr_idx = random.randrange(len(LRS))\n","    batch_idx = random.randrange(len(BATCH_SIZES))\n","    bit_idx = random.randrange(len(BITWIDTHS))\n","    return [layer_count] + neurons + [act_idx, alpha_idx, lr_idx, batch_idx, bit_idx]\n","\n","toolbox.register(\"individual\", tools.initIterate, creator.RA_Individual, init_individual)\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","\n","# ===============================\n","# Helpers\n","# ===============================\n","def clip_genes(ind):\n","    ind[0] = int(np.clip(ind[0], LAYER_MIN, LAYER_MAX))\n","    for i in range(1, 1 + LAYER_MAX):\n","        ind[i] = int(np.clip(ind[i], NEURON_MIN, NEURON_MAX))\n","    base_idx = 1 + LAYER_MAX\n","    ind[base_idx + 0] = int(np.clip(ind[base_idx + 0], 0, len(ACTIVATIONS) - 1))\n","    ind[base_idx + 1] = int(np.clip(ind[base_idx + 1], 0, len(ALPHAS) - 1))\n","    ind[base_idx + 2] = int(np.clip(ind[base_idx + 2], 0, len(LRS) - 1))\n","    ind[base_idx + 3] = int(np.clip(ind[base_idx + 3], 0, len(BATCH_SIZES) - 1))\n","    ind[base_idx + 4] = int(np.clip(ind[base_idx + 4], 0, len(BITWIDTHS) - 1))\n","\n","def decode(ind):\n","    clip_genes(ind)\n","    layer_count = ind[0]\n","    hidden = tuple(int(v) for v in ind[1:1+layer_count])\n","    base_idx = 1 + LAYER_MAX\n","    act = ACTIVATIONS[ind[base_idx + 0]]\n","    alpha = ALPHAS[ind[base_idx + 1]]\n","    lr = LRS[ind[base_idx + 2]]\n","    batch_size = BATCH_SIZES[ind[base_idx + 3]]\n","    bitwidth = BITWIDTHS[ind[base_idx + 4]]\n","    return hidden, act, alpha, lr, batch_size, bitwidth\n","\n","def count_parameters(input_dim, hidden_layer_sizes, output_dim):\n","    dims = [input_dim] + list(hidden_layer_sizes) + [output_dim]\n","    total = 0\n","    for i in range(1, len(dims)):\n","        prev_dim = dims[i-1]\n","        curr_dim = dims[i]\n","        total += (prev_dim + 1) * curr_dim  # bias dahil\n","    return total\n","\n","def make_model(hidden, act, alpha, lr, batch_size, random_state=RANDOM_SEED):\n","    clf = Pipeline([\n","        (\"scaler\", StandardScaler()),\n","        (\"mlp\", MLPClassifier(\n","            hidden_layer_sizes=hidden,\n","            activation=act,\n","            solver=\"adam\",\n","            alpha=alpha,\n","            learning_rate_init=lr,\n","            batch_size=batch_size,\n","            max_iter=30,              # fast scan for EA\n","            early_stopping=True,\n","            n_iter_no_change=5,\n","            random_state=random_state,\n","            tol=1e-4,\n","        ))\n","    ])\n","    return clf\n","\n","def effective_param_norm(P, bitwidth):\n","    P_eff = P * (bitwidth / 32.0)\n","    return P_eff / MAX_PARAMETRE\n","\n","def model_size_kb(P, bitwidth):\n","    return (P * (bitwidth/8)) / 1024.0\n","\n","# Pretty table printer\n","def print_table(headers, rows):\n","    colw = []\n","    for i, h in enumerate(headers):\n","        candidates = [len(str(h))] + [len(str(r[i])) for r in rows]\n","        colw.append(max(candidates) + 2)\n","    def _print(row):\n","        print(\"\".join(str(val).ljust(colw[i]) for i, val in enumerate(row)))\n","    _print(headers)\n","    print(\"-\" * sum(colw))\n","    for r in rows:\n","        _print(r)\n","\n","# ===============================\n","# Resource-aware repair\n","# ===============================\n","def resource_repair(ind):\n","    hidden, act, alpha, lr, batch_size, bitwidth = decode(ind)\n","    hs = list(hidden)\n","    iter_guard = 0\n","    while effective_param_norm(count_parameters(INPUT_DIM, hs, OUTPUT_DIM), bitwidth) > 1.0 and iter_guard < 200:\n","        if not hs:\n","            break\n","        idx = int(np.argmax(hs))\n","        if hs[idx] > NEURON_MIN:\n","            hs[idx] = max(NEURON_MIN, hs[idx] - 2)\n","        else:\n","            candidates = [i for i,v in enumerate(hs) if v > NEURON_MIN]\n","            if not candidates:\n","                break\n","            c = random.choice(candidates)\n","            hs[c] = max(NEURON_MIN, hs[c] - 2)\n","        iter_guard += 1\n","    for i,v in enumerate(hs):\n","        ind[1+i] = int(v)\n","    clip_genes(ind)\n","    return ind\n","\n","# ===============================\n","# Mutation and crossover\n","# ===============================\n","def mutate(ind, indpb=MUT_INDPB):\n","    if random.random() < LAYER_MUTPB:\n","        delta = random.choices([-1, 0, +1], weights=[0.5, 0.3, 0.2], k=1)[0]\n","        ind[0] = int(np.clip(ind[0] + delta, LAYER_MIN, LAYER_MAX))\n","    for i in range(1, 1 + LAYER_MAX):\n","        if random.random() < indpb:\n","            delta = random.choices(REDUCE_DELTAS, weights=REDUCE_WEIGHTS, k=1)[0]\n","            ind[i] = int(np.clip(ind[i] + delta, NEURON_MIN, NEURON_MAX))\n","    base_idx = 1 + LAYER_MAX\n","    if random.random() < indpb:\n","        options = list(range(len(ACTIVATIONS)))\n","        if ind[base_idx + 0] in options:\n","            options.remove(ind[base_idx + 0])\n","        ind[base_idx + 0] = random.choice(options) if options else ind[base_idx + 0]\n","    for j, sizes in enumerate([ALPHAS, LRS, BATCH_SIZES, BITWIDTHS]):\n","        idx = base_idx + 1 + j\n","        if random.random() < indpb:\n","            if random.random() < 0.7:\n","                step = random.choice([-1, +1])\n","                ind[idx] = int(np.clip(ind[idx] + step, 0, len(sizes)-1))\n","            else:\n","                ind[idx] = random.randrange(len(sizes))\n","    clip_genes(ind)\n","    resource_repair(ind)\n","    return (ind,)\n","\n","def mate(p1, p2, indpb=CX_INDPB):\n","    tools.cxUniform(p1, p2, indpb=indpb)\n","    clip_genes(p1); clip_genes(p2)\n","    resource_repair(p1); resource_repair(p2)\n","    return p1, p2\n","\n","toolbox.register(\"mutate\", mutate, indpb=MUT_INDPB)\n","toolbox.register(\"mate\", mate, indpb=CX_INDPB)\n","\n","# ===============================\n","# Evaluation (CV on TRAIN split) + latency proxy\n","# ===============================\n","eval_cache = {}\n","EVAL_COUNTER = {\"count\": 0}\n","\n","def evaluate(ind):\n","    clip_genes(ind)\n","    resource_repair(ind)\n","    key = tuple(ind)\n","    if key in eval_cache:\n","        return eval_cache[key]\n","\n","    hidden, act, alpha, lr, batch_size, bitwidth = decode(ind)\n","    P = count_parameters(INPUT_DIM, hidden, OUTPUT_DIM)\n","    cost_norm = effective_param_norm(P, bitwidth)\n","    if cost_norm > 1.0 or len(hidden) < 1:\n","        res = (0.0, cost_norm, 1e6)\n","        eval_cache[key] = res\n","        return res\n","\n","    cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n","    accs, latencies = [], []\n","\n","    for train_idx, val_idx in cv.split(X_train, y_train):\n","        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n","        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n","\n","        model = make_model(hidden, act, alpha, lr, batch_size, random_state=RANDOM_SEED)\n","        model.fit(X_tr, y_tr)\n","\n","        y_pred = model.predict(X_val)\n","        accs.append(accuracy_score(y_val, y_pred))\n","\n","        for _ in range(WARMUP):\n","            model.predict(X_val)\n","        t0 = time.perf_counter()\n","        for _ in range(LAT_REPEATS):\n","            model.predict(X_val)\n","        t1 = time.perf_counter()\n","        total_preds = LAT_REPEATS * len(X_val)\n","        per_sample_s = (t1 - t0) / max(total_preds, 1)\n","        latencies.append(per_sample_s * 1000.0)\n","\n","    acc_mean = float(np.mean(accs))\n","    lat_ms_raw = float(np.mean(latencies))\n","    lat_ms_eff = lat_ms_raw * (bitwidth / 32.0) ** ETA_LAT\n","\n","    res = (acc_mean, cost_norm, lat_ms_eff)\n","    eval_cache[key] = res\n","    EVAL_COUNTER[\"count\"] += 1\n","    return res\n","\n","toolbox.register(\"evaluate\", evaluate)\n","\n","# ===============================\n","# NSGA-II evolution\n","# ===============================\n","def run_evolution():\n","    pop = toolbox.population(n=POP_SIZE)\n","    for ind in pop:\n","        ind.fitness.values = toolbox.evaluate(ind)\n","    pop = tools.selNSGA2(pop, POP_SIZE)\n","\n","    pareto = tools.ParetoFront()\n","    pareto.update(pop)\n","\n","    for gen in range(1, NGEN + 1):\n","        offspring = algorithms.varAnd(pop, toolbox, cxpb=CXPB, mutpb=MUTPB)\n","        invalid = [ind for ind in offspring if not ind.fitness.valid]\n","        for ind in invalid:\n","            ind.fitness.values = toolbox.evaluate(ind)\n","        pop = tools.selNSGA2(pop + offspring, POP_SIZE)\n","        pareto.update(pop)\n","\n","        fits = np.array([ind.fitness.values for ind in pop])\n","        accs = fits[:,0]; costs = fits[:,1]; lats = fits[:,2]\n","        print(f\"Gen {gen:02d} | acc_avg={np.mean(accs):.4f} acc_max={np.max(accs):.4f} \"\n","              f\"cost_min={np.min(costs):.4f} lat_min_ms={np.min(lats):.4f} \"\n","              f\"| evals={EVAL_COUNTER['count']} cache={len(eval_cache)}\")\n","    return pop, pareto\n","\n","# ===============================\n","# Run\n","# ===============================\n","pop, pareto = run_evolution()\n","\n","# ===============================\n","# Reporting helpers\n","# ===============================\n","def scalar_score(fit_vals):\n","    acc, cost_norm, _lat = fit_vals\n","    return (ALPHA * acc) - (BETA * cost_norm)\n","\n","def decode_full(ind):\n","    hidden, act, alpha, lr, batch_size, bitwidth = decode(ind)\n","    P = count_parameters(INPUT_DIM, hidden, OUTPUT_DIM)\n","    acc, cost_norm, lat_ms = ind.fitness.values\n","    return {\n","        \"hidden\": hidden, \"act\": act, \"alpha\": alpha, \"lr\": lr, \"batch\": batch_size, \"bit\": bitwidth,\n","        \"P\": P, \"acc\": acc, \"cost_norm\": cost_norm, \"lat_ms\": lat_ms, \"scalar_fit\": scalar_score(ind.fitness.values)\n","    }\n","\n","pareto_sorted = sorted(pareto, key=lambda ind: (-ind.fitness.values[0], ind.fitness.values[1], ind.fitness.values[2]))\n","top_k = pareto_sorted[:10]\n","print(\"\\n=== Pareto Öncü Çözümler (ilk 10; CV=TRAIN) ===\")\n","for i, ind in enumerate(top_k, 1):\n","    s = decode_full(ind)\n","    print(f\"#{i}: acc_cv={s['acc']:.4f}, cost_norm={s['cost_norm']:.4f}, lat_ms_cv={s['lat_ms']:.4f}, \"\n","          f\"hidden={s['hidden']}, act={s['act']}, alpha={s['alpha']}, lr={s['lr']}, \"\n","          f\"batch={s['batch']}, bit={s['bit']}, P={s['P']}, scalar_fit={s['scalar_fit']:.4f}\")\n","\n","# Best by scalar score (for report)\n","ea_best = max(pareto, key=lambda ind: scalar_score(ind.fitness.values))\n","ea_best_info = decode_full(ea_best)\n","\n","# ===============================\n","# Baseline CV (on TRAIN) + Test evaluation\n","# ===============================\n","def eval_baseline_cv(hidden=(64,64), act=\"relu\", alpha=1e-4, lr=0.01, batch=128, bitwidth=32):\n","    P = count_parameters(INPUT_DIM, hidden, OUTPUT_DIM)\n","    cost_norm = effective_param_norm(P, bitwidth)\n","\n","    cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n","    accs, latencies = [], []\n","\n","    for train_idx, val_idx in cv.split(X_train, y_train):\n","        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n","        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n","\n","        model = Pipeline([\n","            (\"scaler\", StandardScaler()),\n","            (\"mlp\", MLPClassifier(\n","                hidden_layer_sizes=hidden,\n","                activation=act,\n","                solver=\"adam\",\n","                alpha=alpha,\n","                learning_rate_init=lr,\n","                batch_size=batch,\n","                max_iter=30,\n","                early_stopping=True,\n","                n_iter_no_change=5,\n","                random_state=RANDOM_SEED,\n","                tol=1e-4,\n","            ))\n","        ])\n","        model.fit(X_tr, y_tr)\n","        y_pred = model.predict(X_val)\n","        accs.append(accuracy_score(y_val, y_pred))\n","\n","        for _ in range(WARMUP):\n","            model.predict(X_val)\n","        t0 = time.perf_counter()\n","        for _ in range(LAT_REPEATS):\n","            model.predict(X_val)\n","        t1 = time.perf_counter()\n","        total_preds = LAT_REPEATS * len(X_val)\n","        per_sample_s = (t1 - t0) / max(total_preds, 1)\n","        latencies.append(per_sample_s * 1000.0)\n","\n","    acc_mean = float(np.mean(accs))\n","    lat_ms_raw = float(np.mean(latencies))\n","    lat_ms_eff = lat_ms_raw * (bitwidth / 32.0) ** ETA_LAT\n","    scalar = (ALPHA * acc_mean) - (BETA * cost_norm)\n","\n","    return {\n","        \"hidden\": hidden, \"act\": act, \"alpha\": alpha, \"lr\": lr, \"batch\": batch, \"bit\": bitwidth,\n","        \"P\": P, \"acc_cv\": acc_mean, \"cost_norm\": cost_norm, \"lat_ms_cv\": lat_ms_eff, \"scalar_fit\": scalar,\n","        \"violates_budget\": cost_norm > 1.0\n","    }\n","\n","# Evaluate baselines (CV on TRAIN)\n","baseline_cv = eval_baseline_cv(hidden=(64,64), act=\"relu\", alpha=1e-4, lr=0.01, batch=128, bitwidth=32)  # bütçe-dışı\n","# Bütçe-İçi 32-bit Baseline: hidden=(60,)\n","bl_in_cv = eval_baseline_cv(hidden=(60,), act=\"relu\", alpha=1e-4, lr=0.01, batch=128, bitwidth=32)       # bütçe-içi\n","\n","# Final test evaluation helper\n","def eval_on_test(hidden, act, alpha, lr, batch, bit, max_iter=100):\n","    model = make_model(hidden, act, alpha, lr, batch, random_state=RANDOM_SEED)\n","    model.set_params(mlp__max_iter=max_iter, mlp__early_stopping=False, mlp__n_iter_no_change=10)\n","    model.fit(X_train, y_train)\n","\n","    y_pred = model.predict(X_test)\n","    acc = accuracy_score(y_test, y_pred)\n","\n","    for _ in range(WARMUP):\n","        model.predict(X_test)\n","    t0 = time.perf_counter()\n","    for _ in range(LAT_REPEATS):\n","        model.predict(X_test)\n","    t1 = time.perf_counter()\n","    per_sample_ms = ((t1 - t0) / max(LAT_REPEATS * len(X_test), 1)) * 1000.0\n","    lat_eff = per_sample_ms * (bit / 32.0) ** ETA_LAT\n","    return acc, lat_eff, y_pred\n","\n","# Test eval: EA-Best and Baselines\n","ea_acc_test, ea_lat_test, ea_y_pred = eval_on_test(\n","    ea_best_info['hidden'], ea_best_info['act'], ea_best_info['alpha'],\n","    ea_best_info['lr'], ea_best_info['batch'], ea_best_info['bit'], max_iter=120\n",")\n","bl_acc_test, bl_lat_test, bl_y_pred = eval_on_test(\n","    baseline_cv['hidden'], baseline_cv['act'], baseline_cv['alpha'],\n","    baseline_cv['lr'], baseline_cv['batch'], baseline_cv['bit'], max_iter=120\n",")\n","bl_in_acc_test, bl_in_lat_test, _ = eval_on_test(\n","    bl_in_cv['hidden'], bl_in_cv['act'], bl_in_cv['alpha'],\n","    bl_in_cv['lr'], bl_in_cv['batch'], bl_in_cv['bit'], max_iter=120\n",")\n","\n","# ===============================\n","# Comparison tables (CV and Test)\n","# ===============================\n","print(\"\\n=== EA-Best vs Baseline (CV=TRAIN split) ===\")\n","rows_cv = [\n","    [\"EA-Best\", f\"{ea_best_info['acc']:.4f}\", f\"{ea_best_info['P']}\",\n","     f\"{ea_best_info['cost_norm']:.4f}\", f\"{ea_best_info['bit']}\",\n","     f\"{ea_best_info['lat_ms']:.4f}\", f\"{ea_best_info['scalar_fit']:.4f}\", \"Hayır\"],\n","    [\"Baseline (64,64) - Bütçe Dışı\", f\"{baseline_cv['acc_cv']:.4f}\", f\"{baseline_cv['P']}\",\n","     f\"{baseline_cv['cost_norm']:.4f}\", f\"{baseline_cv['bit']}\",\n","     f\"{baseline_cv['lat_ms_cv']:.4f}\", f\"{baseline_cv['scalar_fit']:.4f}\",\n","     \"Evet\" if baseline_cv['violates_budget'] else \"Hayır\"],\n","    [\"Baseline (60,) - Bütçe İçi\", f\"{bl_in_cv['acc_cv']:.4f}\", f\"{bl_in_cv['P']}\",\n","     f\"{bl_in_cv['cost_norm']:.4f}\", f\"{bl_in_cv['bit']}\",\n","     f\"{bl_in_cv['lat_ms_cv']:.4f}\", f\"{bl_in_cv['scalar_fit']:.4f}\",\n","     \"Evet\" if bl_in_cv['violates_budget'] else \"Hayır\"],\n","]\n","print_table([\"Model\",\"Acc(CV)\",\"Param(P)\",\"Cost_norm\",\"Bit\",\"Latency(ms/sample)\",\"Scalar\",\"Bütçe İhlali?\"], rows_cv)\n","\n","print(\"\\n=== Test Set Karşılaştırması (final training) — Adil Dövüş ===\")\n","rows_test3 = [\n","    [\"Baseline (Bütçe Dışı, 64,64)\", f\"{bl_acc_test:.4f}\", f\"{bl_lat_test:.4f}\",\n","     f\"{baseline_cv['P']}\", f\"{baseline_cv['bit']}\", f\"{model_size_kb(baseline_cv['P'], baseline_cv['bit']):.2f}\",\n","     \"Evet\" if baseline_cv['cost_norm'] > 1.0 else \"Hayır\"],\n","    [\"Baseline (Bütçe-İçi, 60,)\", f\"{bl_in_acc_test:.4f}\", f\"{bl_in_lat_test:.4f}\",\n","     f\"{bl_in_cv['P']}\", f\"{bl_in_cv['bit']}\", f\"{model_size_kb(bl_in_cv['P'], bl_in_cv['bit']):.2f}\",\n","     \"Evet\" if bl_in_cv['cost_norm'] > 1.0 else \"Hayır\"],\n","    [\"EA-Best\", f\"{ea_acc_test:.4f}\", f\"{ea_lat_test:.4f}\",\n","     f\"{ea_best_info['P']}\", f\"{ea_best_info['bit']}\", f\"{model_size_kb(ea_best_info['P'], ea_best_info['bit']):.2f}\",\n","     \"Hayır\"]\n","]\n","print_table([\"Model\",\"Acc(Test)\",\"Latency(ms/sample)\",\"Param(P)\",\"Bit\",\"Model Boyutu(KB)\",\"Bütçe İhlali?\"], rows_test3)\n","\n","ratio_mem_vs_budget_in = model_size_kb(bl_in_cv['P'], bl_in_cv['bit']) / model_size_kb(ea_best_info['P'], ea_best_info['bit'])\n","print(f\"\\nBellek verimliliği: EA-Best, bütçe-içi 32-bit baseline'a göre ~{ratio_mem_vs_budget_in:.1f}× daha küçük.\")\n","\n","print(\"\\nEA-Best mimarisi:\", ea_best_info['hidden'], \"| act:\", ea_best_info['act'],\n","      \"| alpha:\", ea_best_info['alpha'], \"| lr:\", ea_best_info['lr'],\n","      \"| batch:\", ea_best_info['batch'], \"| bit:\", ea_best_info['bit'])\n","print(\"Baseline(64,64) mimarisi:\", baseline_cv['hidden'], \"| act:\", baseline_cv['act'],\n","      \"| alpha:\", baseline_cv['alpha'], \"| lr:\", baseline_cv['lr'],\n","      \"| batch:\", baseline_cv['batch'], \"| bit:\", baseline_cv['bit'])\n","print(\"Baseline(60,) mimarisi:\", bl_in_cv['hidden'], \"| act:\", bl_in_cv['act'],\n","      \"| alpha:\", bl_in_cv['alpha'], \"| lr:\", bl_in_cv['lr'],\n","      \"| batch:\", bl_in_cv['batch'], \"| bit:\", bl_in_cv['bit'])\n","\n","# Optional: Confusion matrices on test (EA-Best ve 64,64 baseline)\n","print(\"\\n--- EA-Best Test Confusion Matrix ---\")\n","print(confusion_matrix(y_test, ea_y_pred))\n","print(\"\\nClassification Report (EA-Best):\\n\", classification_report(y_test, ea_y_pred, digits=4))\n","\n","print(\"\\n--- Baseline(64,64) Test Confusion Matrix ---\")\n","print(confusion_matrix(y_test, bl_y_pred))\n","print(\"\\nClassification Report (Baseline 64,64):\\n\", classification_report(y_test, bl_y_pred, digits=4))\n","\n","# ===============================\n","# Step 2: Şampiyonun Gerçek Gücü — Top-10'u 120 iter ile testte yeniden değerlendir\n","# ===============================\n","top_final = []\n","for ind in top_k:\n","    info = decode_full(ind)\n","    acc_t, lat_t, _ = eval_on_test(info['hidden'], info['act'], info['alpha'],\n","                                   info['lr'], info['batch'], info['bit'], max_iter=120)\n","    top_final.append({\n","        \"hidden\": info['hidden'], \"bit\": info['bit'], \"P\": info['P'],\n","        \"acc_cv\": round(info['acc'], 4), \"acc_test\": round(acc_t, 4),\n","        \"lat_ms_test\": round(lat_t, 4), \"cost_norm\": round(info['cost_norm'], 4),\n","        \"alpha\": info['alpha'], \"lr\": info['lr'], \"batch\": info['batch'], \"act\": info['act'],\n","        \"size_kb\": round(model_size_kb(info['P'], info['bit']), 2)\n","    })\n","\n","df_top = pd.DataFrame(top_final).sort_values(by=[\"acc_test\",\"cost_norm\"], ascending=[False,True])\n","print(\"\\n=== Şampiyonluk Turu: Top-10 Final Test Özeti ===\")\n","print(df_top.to_string(index=False))\n","df_top.to_csv(\"mnist_top10_final.csv\", index=False)\n","\n","# Şampiyonu seç (test doğruluğuna göre)\n","champ = df_top.iloc[0].to_dict()\n","print(\"\\n=== Şampiyon (Test'e göre en iyi) ===\")\n","print(f\"acc_test={champ['acc_test']}, cost_norm={champ['cost_norm']}, lat_ms_test={champ['lat_ms_test']}, \"\n","      f\"P={champ['P']}, bit={champ['bit']}, size_kb={champ['size_kb']}, hidden={champ['hidden']}, \"\n","      f\"act={champ['act']}, alpha={champ['alpha']}, lr={champ['lr']}, batch={champ['batch']}\")\n","\n","# Bellek oranları\n","mem_ratio_vs_bl_out = model_size_kb(baseline_cv['P'], baseline_cv['bit']) / champ['size_kb']\n","mem_ratio_vs_bl_in  = model_size_kb(bl_in_cv['P'], bl_in_cv['bit']) / champ['size_kb']\n","print(f\"\\nBellek oranı: Şampiyon, bütçe-dışı baseline’a göre ~{mem_ratio_vs_bl_out:.1f}×; \"\n","      f\"bütçe-içi baseline’a göre ~{mem_ratio_vs_bl_in:.1f}× daha küçük.\")\n","\n","# --- Şampiyonu tekrar değerlendir (y_pred ile) ve nihai adil dövüş tablosu ---\n","ch_hidden = champ['hidden']; ch_act = champ['act']; ch_alpha = champ['alpha']\n","ch_lr = champ['lr']; ch_batch = champ['batch']; ch_bit = int(champ['bit'])\n","ch_acc, ch_lat, ch_pred = eval_on_test(ch_hidden, ch_act, ch_alpha, ch_lr, ch_batch, ch_bit, max_iter=120)\n","\n","print(\"\\n--- EA-Champion Test Confusion Matrix ---\")\n","print(confusion_matrix(y_test, ch_pred))\n","print(\"\\nClassification Report (EA-Champion):\\n\", classification_report(y_test, ch_pred, digits=4))\n","\n","rows_test_champ = [\n","    [\"Baseline (Bütçe Dışı, 64,64)\", f\"{bl_acc_test:.4f}\", f\"{bl_lat_test:.4f}\",\n","     f\"{baseline_cv['P']}\", f\"{baseline_cv['bit']}\", f\"{model_size_kb(baseline_cv['P'], baseline_cv['bit']):.2f}\",\n","     \"Evet\" if baseline_cv['cost_norm'] > 1.0 else \"Hayır\"],\n","    [\"Baseline (Bütçe-İçi, 60,)\", f\"{bl_in_acc_test:.4f}\", f\"{bl_in_lat_test:.4f}\",\n","     f\"{bl_in_cv['P']}\", f\"{bl_in_cv['bit']}\", f\"{model_size_kb(bl_in_cv['P'], bl_in_cv['bit']):.2f}\",\n","     \"Evet\" if bl_in_cv['cost_norm'] > 1.0 else \"Hayır\"],\n","    [\"EA-Champion\", f\"{ch_acc:.4f}\", f\"{ch_lat:.4f}\",\n","     f\"{champ['P']}\", f\"{ch_bit}\", f\"{champ['size_kb']:.2f}\", \"Hayır\"]\n","]\n","print(\"\\n=== Nihai Adil Dövüş (Şampiyon ile) ===\")\n","print_table([\"Model\",\"Acc(Test)\",\"Latency(ms/sample)\",\"Param(P)\",\"Bit\",\"Model Boyutu(KB)\",\"Bütçe İhlali?\"], rows_test_champ)\n","\n","print(\"\\nNotlar:\")\n","print(\"- EA, TRAIN split üzerinde CV ile optimize edilir; final performans TEST split üzerinde raporlanır.\")\n","print(\"- Latency, scikit-learn MLP için gerçek quantization etkisini modellemediğinden proxy ile hesaplanır.\")\n","print(\"- Daha yüksek doğruluk için arama uzayını genişletebilirsiniz (NEURON_MAX=128, LAYER_MAX=5, MAX_PARAMETRE=100_000) ve NGEN/POP_SIZE’i artırabilirsiniz.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u1FXIRaim25y","executionInfo":{"status":"ok","timestamp":1763131865318,"user_tz":-180,"elapsed":1258916,"user":{"displayName":"burak poyraz","userId":"10456505299067759356"}},"outputId":"75988a96-557e-4834-cf2a-66e85e700dfb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["MNIST indiriliyor (OpenML)...\n","Subset hazır: X.shape=(10000, 784), sınıf sayısı=10\n","Gen 01 | acc_avg=0.8733 acc_max=0.9238 cost_min=0.0715 lat_min_ms=0.0030 | evals=58 cache=58\n","Gen 02 | acc_avg=0.9001 acc_max=0.9238 cost_min=0.0388 lat_min_ms=0.0027 | evals=82 cache=82\n","Gen 03 | acc_avg=0.9032 acc_max=0.9238 cost_min=0.0388 lat_min_ms=0.0026 | evals=108 cache=108\n","Gen 04 | acc_avg=0.9026 acc_max=0.9238 cost_min=0.0358 lat_min_ms=0.0026 | evals=128 cache=128\n","Gen 05 | acc_avg=0.9049 acc_max=0.9292 cost_min=0.0319 lat_min_ms=0.0026 | evals=155 cache=155\n","Gen 06 | acc_avg=0.9095 acc_max=0.9292 cost_min=0.0319 lat_min_ms=0.0025 | evals=180 cache=180\n","Gen 07 | acc_avg=0.9065 acc_max=0.9292 cost_min=0.0319 lat_min_ms=0.0025 | evals=204 cache=204\n","Gen 08 | acc_avg=0.9036 acc_max=0.9292 cost_min=0.0319 lat_min_ms=0.0025 | evals=228 cache=228\n","Gen 09 | acc_avg=0.9053 acc_max=0.9292 cost_min=0.0319 lat_min_ms=0.0025 | evals=255 cache=255\n","Gen 10 | acc_avg=0.9044 acc_max=0.9292 cost_min=0.0319 lat_min_ms=0.0025 | evals=278 cache=278\n","\n","=== Pareto Öncü Çözümler (ilk 10; CV=TRAIN) ===\n","#1: acc_cv=0.9292, cost_norm=0.7543, lat_ms_cv=0.0082, hidden=(46, 28), act=relu, alpha=0.01, lr=0.003, batch=32, bit=32, P=37716, scalar_fit=0.5925\n","#2: acc_cv=0.9267, cost_norm=0.2266, lat_ms_cv=0.0031, hidden=(57,), act=relu, alpha=0.01, lr=0.003, batch=32, bit=8, P=45325, scalar_fit=0.6961\n","#3: acc_cv=0.9254, cost_norm=0.1897, lat_ms_cv=0.0031, hidden=(46, 32), act=relu, alpha=0.01, lr=0.003, batch=32, bit=8, P=37944, scalar_fit=0.7024\n","#4: acc_cv=0.9250, cost_norm=0.1948, lat_ms_cv=0.0029, hidden=(49,), act=relu, alpha=0.01, lr=0.003, batch=32, bit=8, P=38965, scalar_fit=0.7010\n","#5: acc_cv=0.9238, cost_norm=0.1829, lat_ms_cv=0.0030, hidden=(46,), act=relu, alpha=0.01, lr=0.003, batch=64, bit=8, P=36580, scalar_fit=0.7024\n","#6: acc_cv=0.9218, cost_norm=0.1829, lat_ms_cv=0.0030, hidden=(46,), act=relu, alpha=0.01, lr=0.003, batch=128, bit=8, P=36580, scalar_fit=0.7008\n","#7: acc_cv=0.9216, cost_norm=0.1948, lat_ms_cv=0.0029, hidden=(49,), act=relu, alpha=0.01, lr=0.001, batch=32, bit=8, P=38965, scalar_fit=0.6983\n","#8: acc_cv=0.9179, cost_norm=0.1312, lat_ms_cv=0.0034, hidden=(33,), act=relu, alpha=1e-05, lr=0.003, batch=32, bit=8, P=26245, scalar_fit=0.7081\n","#9: acc_cv=0.9176, cost_norm=0.0994, lat_ms_cv=0.0028, hidden=(25,), act=relu, alpha=0.0001, lr=0.003, batch=32, bit=8, P=19885, scalar_fit=0.7142\n","#10: acc_cv=0.9121, cost_norm=0.0835, lat_ms_cv=0.0030, hidden=(21,), act=relu, alpha=0.001, lr=0.01, batch=64, bit=8, P=16705, scalar_fit=0.7130\n","\n","=== EA-Best vs Baseline (CV=TRAIN split) ===\n","Model                          Acc(CV)  Param(P)  Cost_norm  Bit  Latency(ms/sample)  Scalar  Bütçe İhlali?  \n","-------------------------------------------------------------------------------------------------------------\n","EA-Best                        0.9176   19885     0.0994     8    0.0028              0.7142  Hayır          \n","Baseline (64,64) - Bütçe Dışı  0.9199   55050     1.1010     32   0.0087              0.5157  Evet           \n","Baseline (60,) - Bütçe İçi     0.9173   47710     0.9542     32   0.0082              0.5430  Hayır          \n","\n","=== Test Set Karşılaştırması (final training) — Adil Dövüş ===\n","Model                         Acc(Test)  Latency(ms/sample)  Param(P)  Bit  Model Boyutu(KB)  Bütçe İhlali?  \n","-------------------------------------------------------------------------------------------------------------\n","Baseline (Bütçe Dışı, 64,64)  0.9350     0.0086              55050     32   215.04            Evet           \n","Baseline (Bütçe-İçi, 60,)     0.9425     0.0087              47710     32   186.37            Hayır          \n","EA-Best                       0.9305     0.0028              19885     8    19.42             Hayır          \n","\n","Bellek verimliliği: EA-Best, bütçe-içi 32-bit baseline'a göre ~9.6× daha küçük.\n","\n","EA-Best mimarisi: (25,) | act: relu | alpha: 0.0001 | lr: 0.003 | batch: 32 | bit: 8\n","Baseline(64,64) mimarisi: (64, 64) | act: relu | alpha: 0.0001 | lr: 0.01 | batch: 128 | bit: 32\n","Baseline(60,) mimarisi: (60,) | act: relu | alpha: 0.0001 | lr: 0.01 | batch: 128 | bit: 32\n","\n","--- EA-Best Test Confusion Matrix ---\n","[[189   0   1   1   0   3   2   0   0   1]\n"," [  0 221   2   1   0   0   0   0   1   0]\n"," [  1   1 181   2   4   0   4   2   5   0]\n"," [  1   1   1 183   0   4   1   3   5   5]\n"," [  0   0   4   0 182   0   1   0   0   8]\n"," [  0   2   1   2   1 166   3   1   3   1]\n"," [  0   1   3   0   1   0 191   0   1   0]\n"," [  0   2   0   3   1   0   0 196   1   5]\n"," [  1   4   4   1   2   3   1   0 175   4]\n"," [  1   1   1   0   6   3   0   8   2 177]]\n","\n","Classification Report (EA-Best):\n","               precision    recall  f1-score   support\n","\n","           0     0.9793    0.9594    0.9692       197\n","           1     0.9485    0.9822    0.9651       225\n","           2     0.9141    0.9050    0.9095       200\n","           3     0.9482    0.8971    0.9219       204\n","           4     0.9239    0.9333    0.9286       195\n","           5     0.9274    0.9222    0.9248       180\n","           6     0.9409    0.9695    0.9550       197\n","           7     0.9333    0.9423    0.9378       208\n","           8     0.9067    0.8974    0.9021       195\n","           9     0.8806    0.8894    0.8850       199\n","\n","    accuracy                         0.9305      2000\n","   macro avg     0.9303    0.9298    0.9299      2000\n","weighted avg     0.9306    0.9305    0.9304      2000\n","\n","\n","--- Baseline(64,64) Test Confusion Matrix ---\n","[[188   0   0   1   0   1   2   1   2   2]\n"," [  0 223   2   0   0   0   0   0   0   0]\n"," [  0   2 185   5   1   0   1   2   3   1]\n"," [  0   3   2 184   1   3   1   2   4   4]\n"," [  0   0   0   0 184   0   1   0   2   8]\n"," [  3   0   2   3   0 165   2   0   5   0]\n"," [  0   1   0   0   0   0 193   0   3   0]\n"," [  0   3   1   2   2   2   0 188   3   7]\n"," [  1   6   2   1   1   2   3   1 174   4]\n"," [  1   0   0   2   3   3   1   3   0 186]]\n","\n","Classification Report (Baseline 64,64):\n","               precision    recall  f1-score   support\n","\n","           0     0.9741    0.9543    0.9641       197\n","           1     0.9370    0.9911    0.9633       225\n","           2     0.9536    0.9250    0.9391       200\n","           3     0.9293    0.9020    0.9154       204\n","           4     0.9583    0.9436    0.9509       195\n","           5     0.9375    0.9167    0.9270       180\n","           6     0.9461    0.9797    0.9626       197\n","           7     0.9543    0.9038    0.9284       208\n","           8     0.8878    0.8923    0.8900       195\n","           9     0.8774    0.9347    0.9051       199\n","\n","    accuracy                         0.9350      2000\n","   macro avg     0.9355    0.9343    0.9346      2000\n","weighted avg     0.9356    0.9350    0.9350      2000\n","\n","\n","=== Şampiyonluk Turu: Top-10 Final Test Özeti ===\n","  hidden  bit     P  acc_cv  acc_test  lat_ms_test  cost_norm   alpha    lr  batch  act  size_kb\n","   (49,)    8 38965  0.9250    0.9470       0.0030     0.1948 0.01000 0.003     32 relu    38.05\n","   (49,)    8 38965  0.9216    0.9450       0.0030     0.1948 0.01000 0.001     32 relu    38.05\n","(46, 32)    8 37944  0.9254    0.9410       0.0038     0.1897 0.01000 0.003     32 relu    37.05\n","   (46,)    8 36580  0.9218    0.9385       0.0035     0.1829 0.01000 0.003    128 relu    35.72\n","   (33,)    8 26245  0.9179    0.9375       0.0028     0.1312 0.00001 0.003     32 relu    25.63\n","   (46,)    8 36580  0.9238    0.9375       0.0036     0.1829 0.01000 0.003     64 relu    35.72\n","   (25,)    8 19885  0.9176    0.9305       0.0028     0.0994 0.00010 0.003     32 relu    19.42\n","   (57,)    8 45325  0.9267    0.9285       0.0031     0.2266 0.01000 0.003     32 relu    44.26\n","(46, 28)   32 37716  0.9292    0.9255       0.0085     0.7543 0.01000 0.003     32 relu   147.33\n","   (21,)    8 16705  0.9121    0.9130       0.0029     0.0835 0.00100 0.010     64 relu    16.31\n","\n","=== Şampiyon (Test'e göre en iyi) ===\n","acc_test=0.947, cost_norm=0.1948, lat_ms_test=0.003, P=38965, bit=8, size_kb=38.05, hidden=(49,), act=relu, alpha=0.01, lr=0.003, batch=32\n","\n","Bellek oranı: Şampiyon, bütçe-dışı baseline’a göre ~5.7×; bütçe-içi baseline’a göre ~4.9× daha küçük.\n","\n","--- EA-Champion Test Confusion Matrix ---\n","[[191   0   0   1   0   1   2   1   0   1]\n"," [  0 222   2   1   0   0   0   0   0   0]\n"," [  2   0 187   2   1   0   1   2   5   0]\n"," [  1   1   1 189   0   4   2   3   2   1]\n"," [  0   0   1   0 184   0   1   1   0   8]\n"," [  1   0   1   3   0 169   4   0   2   0]\n"," [  1   2   2   0   1   0 191   0   0   0]\n"," [  0   2   0   1   0   1   0 203   0   1]\n"," [  1   5   1   0   0   2   3   1 179   3]\n"," [  1   0   0   0   6   3   0   7   3 179]]\n","\n","Classification Report (EA-Champion):\n","               precision    recall  f1-score   support\n","\n","           0     0.9646    0.9695    0.9671       197\n","           1     0.9569    0.9867    0.9716       225\n","           2     0.9590    0.9350    0.9468       200\n","           3     0.9594    0.9265    0.9426       204\n","           4     0.9583    0.9436    0.9509       195\n","           5     0.9389    0.9389    0.9389       180\n","           6     0.9363    0.9695    0.9526       197\n","           7     0.9312    0.9760    0.9531       208\n","           8     0.9372    0.9179    0.9275       195\n","           9     0.9275    0.8995    0.9133       199\n","\n","    accuracy                         0.9470      2000\n","   macro avg     0.9469    0.9463    0.9464      2000\n","weighted avg     0.9471    0.9470    0.9469      2000\n","\n","\n","=== Nihai Adil Dövüş (Şampiyon ile) ===\n","Model                         Acc(Test)  Latency(ms/sample)  Param(P)  Bit  Model Boyutu(KB)  Bütçe İhlali?  \n","-------------------------------------------------------------------------------------------------------------\n","Baseline (Bütçe Dışı, 64,64)  0.9350     0.0086              55050     32   215.04            Evet           \n","Baseline (Bütçe-İçi, 60,)     0.9425     0.0087              47710     32   186.37            Hayır          \n","EA-Champion                   0.9470     0.0030              38965     8    38.05             Hayır          \n","\n","Notlar:\n","- EA, TRAIN split üzerinde CV ile optimize edilir; final performans TEST split üzerinde raporlanır.\n","- Latency, scikit-learn MLP için gerçek quantization etkisini modellemediğinden proxy ile hesaplanır.\n","- Daha yüksek doğruluk için arama uzayını genişletebilirsiniz (NEURON_MAX=128, LAYER_MAX=5, MAX_PARAMETRE=100_000) ve NGEN/POP_SIZE’i artırabilirsiniz.\n"]}]}]}